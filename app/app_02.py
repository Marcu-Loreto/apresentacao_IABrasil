# app.py
import os
import streamlit as st
from dotenv import load_dotenv
from streamlit.components.v1 import html as st_html
from openai import OpenAI
import json
from pathlib import Path
import re
from io import BytesIO
from collections import Counter
import base64
import time
import pickle
from datetime import datetime

# Imports opcionais
try:
    from difflib import SequenceMatcher
    _SEQUENCEMATCHER_AVAILABLE = True
except Exception:
    SequenceMatcher = None
    _SEQUENCEMATCHER_AVAILABLE = False

try:
    from wordcloud import WordCloud
    _WORDCLOUD_AVAILABLE = True
except Exception:
    _WORDCLOUD_AVAILABLE = False

try:
    import networkx as nx
    from pyvis.network import Network
    _GRAPH_AVAILABLE = True
except Exception:
    nx = None
    Network = None
    _GRAPH_AVAILABLE = False

# Carrega variÃ¡veis do .env
load_dotenv()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CORRETOR ORTOGRÃFICO INTEGRADO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# DicionÃ¡rio de correÃ§Ãµes comuns em PT-BR
CORREÃ‡Ã•ES_ORTOGRÃFICAS = {
    # Erros comuns de digitaÃ§Ã£o
    "tbm": "tambÃ©m",
    "vc": "vocÃª",
    "tb": "tambÃ©m",
    "q": "que",
    "eh": "Ã©",
    "mt": "muito",
    "td": "tudo",
    "blz": "beleza",
    "obg": "obrigado",
    "vlw": "valeu",
    "pq": "porque",
    "Ã±": "nÃ£o",
    "oq": "o que",
    "dps": "depois",
    "hj": "hoje",
    "amg": "amigo",
    "msg": "mensagem",
    "msm": "mesmo",
    "cmg": "comigo",
    # Erros de acentuaÃ§Ã£o comuns
    "nao": "nÃ£o",
    "entao": "entÃ£o",
    "voce": "vocÃª",
    "esta": "estÃ¡",
    "ate": "atÃ©",
    "mas": "mas",
    "porem": "porÃ©m",
    "tambem": "tambÃ©m",
    "numero": "nÃºmero",
    "telefone": "telefone",
    "codigo": "cÃ³digo",
    "pedido": "pedido",
    "prazo": "prazo",
    "endereco": "endereÃ§o",
    "reclamacao": "reclamaÃ§Ã£o",
    "solucao": "soluÃ§Ã£o",
    "atencao": "atenÃ§Ã£o",
    "informacao": "informaÃ§Ã£o",
}


def corrigir_palavra(palavra: str) -> str:
    """
    Corrige uma palavra usando dicionÃ¡rio de correÃ§Ãµes.
    MantÃ©m capitalizaÃ§Ã£o original.
    """
    palavra_lower = palavra.lower()
    
    # Verifica se estÃ¡ no dicionÃ¡rio de correÃ§Ãµes
    if palavra_lower in CORREÃ‡Ã•ES_ORTOGRÃFICAS:
        correcao = CORREÃ‡Ã•ES_ORTOGRÃFICAS[palavra_lower]
        
        # Preserva capitalizaÃ§Ã£o
        if palavra[0].isupper():
            return correcao.capitalize()
        return correcao
    
    return palavra


def corrigir_texto(texto: str) -> str:
    """
    Corrige ortografia de um texto completo.
    Preserva pontuaÃ§Ã£o e estrutura.
    """
    # Separa palavras mantendo pontuaÃ§Ã£o
    tokens = re.findall(r'\b\w+\b|[^\w\s]', texto)
    
    corrigido = []
    for token in tokens:
        if re.match(r'\w+', token):  # Ã‰ uma palavra
            corrigido.append(corrigir_palavra(token))
        else:  # Ã‰ pontuaÃ§Ã£o ou espaÃ§o
            corrigido.append(token)
    
    return ' '.join(corrigido)


def corrigir_com_llm(texto: str, client: OpenAI, modelo: str) -> str:
    """
    CorreÃ§Ã£o ortogrÃ¡fica usando LLM (fallback para casos complexos).
    Usa cache para evitar chamadas repetidas.
    """
    cache_key = f"correcao_{hash(texto)}"
    
    if cache_key in st.session_state:
        return st.session_state[cache_key]
    
    try:
        prompt = f"""Corrija APENAS erros ortogrÃ¡ficos do texto abaixo.
Mantenha a mesma estrutura, pontuaÃ§Ã£o e significado.
Retorne SOMENTE o texto corrigido, sem explicaÃ§Ãµes.

Texto: {texto}

Texto corrigido:"""
        
        resp = client.chat.completions.create(
            model=modelo,
            messages=[
                {"role": "system", "content": "VocÃª Ã© um corretor ortogrÃ¡fico. Retorne apenas o texto corrigido."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,
            max_tokens=300
        )
        
        corrigido = resp.choices[0].message.content.strip()
        st.session_state[cache_key] = corrigido
        return corrigido
        
    except Exception as e:
        st.warning(f"âš ï¸ CorreÃ§Ã£o LLM falhou: {e}")
        return texto


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ASSISTENTE DEFINIDO 100% NO CÃ“DIGO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SYSTEM_PROMPT = """
VocÃª Ã© o Assistente de Atendimento e ConciliaÃ§Ã£o da empresa.
MissÃ£o: resolver solicitaÃ§Ãµes de clientes com rapidez, cordialidade e foco em acordos justos.
VocÃª Ã© um assistente que responde apenas apÃ³s a primeira mensagem do usuÃ¡rio.
NÃ£o peÃ§a nome nem dados pessoais por padrÃ£o.
Se a conversa estiver vazia, nÃ£o diga nada.

PrincÃ­pios:
1) Clareza, objetividade e empatia; trate o cliente pelo nome se fornecido.
2) Confirme entendimento do caso em 1 frase antes de propor soluÃ§Ã£o.
3) Traga opÃ§Ãµes de conciliaÃ§Ã£o: reenvio, abatimento, reembolso (parcial/total), crÃ©dito em conta, cupom.
4) Explique prazos, documentos necessÃ¡rios e prÃ³ximos passos com bullets curtos.
5) Se faltar informaÃ§Ã£o, faÃ§a no mÃ¡ximo 2 perguntas diretas e relevantes.
6) Evite jargÃµes; linguagem simples e educada.
7) Respeite polÃ­ticas: nÃ£o prometa o que nÃ£o pode cumprir; se necessÃ¡rio, escale ao time responsÃ¡vel.
8) ProteÃ§Ã£o de dados: nÃ£o invente dados do cliente; confirme somente o que foi informado.

Formato da resposta:
- Resumo do caso:
- SoluÃ§Ã£o proposta:
- PrÃ³ximos passos:
- ObservaÃ§Ãµes:

Exemplo de tom:
"Entendi o ocorrido e quero resolver isso da forma mais rÃ¡pida e justa para vocÃª."
"""

# ConfiguraÃ§Ã£o do assistente
CONFIG = {
    "modelo_padrao": os.getenv("OPENAI_MODEL", "gpt-4o-mini"),
    "modelo_sentimento": os.getenv("OPENAI_SENTIMENT_MODEL", "gpt-4o-mini"),
    "temperatura_padrao": 0.3,
    "max_tokens_padrao": 500,
    "max_contexto_mensagens": 20,  # Limita histÃ³rico enviado Ã  API
    "max_contexto_rag": 3,
    "sentimento_habilitado": True,
    "correcao_ortografica": True,  # NOVO: habilita correÃ§Ã£o
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# VALIDAÃ‡ÃƒO E CLIENTE OPENAI
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# ValidaÃ§Ã£o de seguranÃ§a
if not OPENAI_API_KEY:
    st.error("ğŸ”’ OPENAI_API_KEY nÃ£o encontrada. Defina no arquivo .env")
    st.stop()

if not OPENAI_API_KEY.startswith("sk-"):
    st.error("ğŸ”’ OPENAI_API_KEY invÃ¡lida. Deve comeÃ§ar com 'sk-'")
    st.stop()

client = OpenAI(api_key=OPENAI_API_KEY)


def obter_mensagens_completas():
    """
    Retorna mensagens com janela deslizante para otimizar tokens.
    Inclui system message + Ãºltimas N mensagens.
    """
    max_msgs = CONFIG["max_contexto_mensagens"]
    msgs_usuario = st.session_state.get("lista_mensagens", [])
    
    # Pega Ãºltimas N mensagens
    msgs_recentes = msgs_usuario[-max_msgs:] if len(msgs_usuario) > max_msgs else msgs_usuario
    
    # Adiciona system message no inÃ­cio
    return [{"role": "system", "content": SYSTEM_PROMPT}] + msgs_recentes


def call_llm(
    user_message: str,
    *,
    model: str = None,
    temperature: float = None,
    max_tokens: int = None,
) -> str:
    """
    Chamada robusta Ã  API OpenAI com parÃ¢metros configurÃ¡veis.
    """
    model = model or CONFIG["modelo_padrao"]
    temperature = temperature if temperature is not None else CONFIG["temperatura_padrao"]
    max_tokens = max_tokens or CONFIG["max_tokens_padrao"]
    
    messages = obter_mensagens_completas()
    messages.append({"role": "user", "content": user_message})
    
    try:
        resp = client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens,
        )
        return (resp.choices[0].message.content or "").strip()
    except Exception as e:
        st.error(f"âŒ Erro na API OpenAI: {str(e)}")
        return f"Desculpe, ocorreu um erro ao processar sua mensagem: {str(e)}"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ANÃLISE DE SENTIMENTO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _formatar_prompt_sentimento(texto: str) -> str:
    return (
        "VocÃª Ã© um classificador de sentimento. Classifique a mensagem a seguir.\n"
        "Responda APENAS com JSON vÃ¡lido com as chaves exatamente assim:\n"
        '{"label":"positivo|neutro|negativo","confidence":0.0-1.0,"emotions":["..."],"reason":"..."}\n'
        "Mensagem:\n"
        f"{texto.strip()}"
    )


def analisar_sentimento(texto: str, modelo_sentimento: str):
    """
    Analisa sentimento usando LLM.
    Retorna dict com label, confidence, emotions e reason.
    """
    try:
        resp = client.chat.completions.create(
            model=modelo_sentimento,
            messages=[
                {"role": "system", "content": "Retorne JSON estrito."},
                {"role": "user", "content": _formatar_prompt_sentimento(texto)},
            ],
            temperature=0.0,
            max_tokens=150,
        )
        
        raw = resp.choices[0].message.content.strip()
        
        # Remove markdown se presente
        if raw.startswith("```"):
            raw = re.sub(r'```json\s*|\s*```', '', raw)
        
        data = json.loads(raw)
        
        # ValidaÃ§Ã£o e normalizaÃ§Ã£o
        label = str(data.get("label", "neutro")).lower()
        if label not in {"positivo", "neutro", "negativo"}:
            label = "neutro"
        
        conf = float(data.get("confidence", 0.5))
        conf = max(0.0, min(1.0, conf))
        
        emotions = data.get("emotions", [])
        if not isinstance(emotions, list):
            emotions = [str(emotions)]
        
        reason = str(data.get("reason", "")).strip()
        
        return {
            "label": label,
            "confidence": conf,
            "emotions": [str(e) for e in emotions if str(e).strip()],
            "reason": reason,
        }
        
    except Exception as e:
        return {
            "label": "neutro",
            "confidence": 0.0,
            "emotions": [],
            "reason": f"Falha na anÃ¡lise: {e}",
        }


def _score_from_label(label: str, confidence: float) -> float:
    """Converte rÃ³tulo + confianÃ§a em score âˆˆ [-1, 1]."""
    sgn = 1 if label == "positivo" else (-1 if label == "negativo" else 0)
    c = max(0.0, min(1.0, float(confidence)))
    return round(sgn * c, 3)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TOKENIZAÃ‡ÃƒO PT-BR (WordCloud + Grafo)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

_PT_STOPWORDS = {
    "a", "Ã ", "Ã s", "ao", "aos", "as", "o", "os", "um", "uma", "uns", "umas",
    "de", "da", "do", "das", "dos", "dÃ¡", "dÃ£o", "em", "no", "na", "nos", "nas",
    "por", "para", "pra", "com", "sem", "entre", "sobre", "sob", "atÃ©", "apÃ³s",
    "que", "se", "Ã©", "ser", "sÃ£o", "era", "eram", "foi", "fui", "vai", "vou",
    "e", "ou", "mas", "como", "quando", "onde", "qual", "quais", "porque", "porquÃª",
    "jÃ¡", "nÃ£o", "sim", "tambÃ©m", "mais", "menos", "muito", "muita", "muitos", "muitas",
    "meu", "minha", "meus", "minhas", "seu", "sua", "seus", "suas",
    "depois", "antes", "este", "esta", "estes", "estas", "isso", "isto",
    "aquele", "aquela", "aqueles", "aquelas", "lhe", "lhes", "ele", "ela", "eles", "elas",
    "vocÃª", "vocÃªs", "nÃ³s", "nosso", "nossa", "nossos", "nossas",
}


def tokenize_pt(texto: str, corrigir: bool = True):
    """
    Tokeniza texto em PT-BR, remove stopwords e opcionalmente corrige ortografia.
    """
    # NOVO: Aplica correÃ§Ã£o ortogrÃ¡fica antes de tokenizar
    if corrigir and CONFIG.get("correcao_ortografica", True):
        texto = corrigir_texto(texto)
    
    texto = texto.lower()
    tokens = re.findall(r'[a-zA-ZÃ€-Ã¿]+', texto)
    tokens = [t for t in tokens if len(t) >= 3 and t not in _PT_STOPWORDS]
    
    return tokens


def gerar_wordcloud(corpus_text: str, width: int = 450, height: int = 280):
    """Gera WordCloud a partir do corpus."""
    if not corpus_text.strip():
        return None, "Digite algo para iniciar a nuvem de palavras."
    
    if not _WORDCLOUD_AVAILABLE:
        return None, "Pacote 'wordcloud' nÃ£o encontrado. Instale: pip install wordcloud"
    
    try:
        wc = WordCloud(
            width=width,
            height=height,
            background_color="white",
            collocations=False,
            max_words=100,
            relative_scaling=0.5,
            min_font_size=8
        )
        wc.generate(corpus_text)
        
        img = wc.to_image()
        buf = BytesIO()
        img.save(buf, format="PNG")
        buf.seek(0)
        
        return buf, None
        
    except Exception as e:
        return None, f"Erro ao gerar wordcloud: {e}"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# GRAFO DE PALAVRAS (CoocorrÃªncias)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def build_word_graph(token_sequences, min_edge_weight: int = 1, max_nodes: int = 500):
    """
    ConstrÃ³i grafo de coocorrÃªncias com limite de nÃ³s para performance.
    """
    if not _GRAPH_AVAILABLE:
        return None
    
    G = nx.Graph()
    node_counts = Counter()
    edge_counts = Counter()
    
    # Conta frequÃªncias
    for seq in token_sequences:
        node_counts.update(seq)
        for i in range(len(seq) - 1):
            a, b = seq[i], seq[i + 1]
            if a == b:
                continue
            edge = tuple(sorted((a, b)))
            edge_counts[edge] += 1
    
    # Limita a top N palavras mais frequentes
    if len(node_counts) > max_nodes:
        top_words = set([w for w, _ in node_counts.most_common(max_nodes)])
        node_counts = {w: c for w, c in node_counts.items() if w in top_words}
        edge_counts = {
            (a, b): c for (a, b), c in edge_counts.items()
            if a in top_words and b in top_words
        }
    
    # Adiciona nÃ³s
    for w, c in node_counts.items():
        G.add_node(w, count=int(c))
    
    # Adiciona arestas com peso mÃ­nimo
    for (a, b), w in edge_counts.items():
        if w >= max(1, int(min_edge_weight)):
            G.add_edge(a, b, weight=int(w))
    
    return G


def subgraph_paths_to_target(G, target: str, max_depth: int = 4):
    """Extrai subgrafo com caminhos atÃ© o alvo."""
    if G is None or target not in G:
        return None
    
    visited = {target}
    frontier = {target}
    depth = 0
    
    while frontier and depth < max_depth:
        next_frontier = set()
        for u in frontier:
            for v in G.neighbors(u):
                if v not in visited:
                    visited.add(v)
                    next_frontier.add(v)
        frontier = next_frontier
        depth += 1
    
    return G.subgraph(visited).copy()


def render_graph_pyvis(
    G,
    highlight_target: str = None,
    height_px: int = 600,
    dark_mode: bool = False
):
    """Renderiza grafo com PyVis (interativo)."""
    if not _GRAPH_AVAILABLE or G is None or len(G) == 0:
        return None, "Grafo indisponÃ­vel ou sem dados."
    
    bg = "#0f172a" if dark_mode else "#ffffff"
    fg = "#e5e7eb" if dark_mode else "#333333"
    
    net = Network(
        height=f"{height_px}px",
        width="100%",
        bgcolor=bg,
        font_color=fg,
        notebook=False,
        directed=False,
    )
    
    net.barnes_hut(
        gravity=-2000,
        central_gravity=0.3,
        spring_length=160,
        spring_strength=0.01,
        damping=0.9,
    )
    
    # NormalizaÃ§Ã£o de tamanhos
    node_counts = nx.get_node_attributes(G, "count")
    max_count = max(node_counts.values()) if node_counts else 1
    
    for node, data in G.nodes(data=True):
        count = int(data.get("count", 1))
        size = 10 + (30 * (count / max_count))
        
        color_high = "#34d399" if dark_mode else "#10b981"
        color_norm = "#93c5fd" if dark_mode else "#60a5fa"
        color = color_high if node == highlight_target else color_norm
        
        title = f"{node}<br/>freq: {count}"
        net.add_node(node, label=node, size=size, color=color, title=title)
    
    for u, v, data in G.edges(data=True):
        w = int(data.get("weight", 1))
        width = 1 + min(10, w)
        title = f"{u} â€” {v}<br/>coocorrÃªncias: {w}"
        net.add_edge(u, v, value=w, width=width, title=title)
    
    return net.generate_html(), None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PERSISTÃŠNCIA DE DADOS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def salvar_sessao():
    """Salva estado da sessÃ£o em arquivo."""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"sessao_{timestamp}.pkl"
    
    try:
        data = {
            "mensagens": st.session_state.get("lista_mensagens", []),
            "sentiment_history": st.session_state.get("sentiment_history", []),
            "corpus": st.session_state.get("user_corpus_text", ""),
            "tokens": st.session_state.get("user_token_sequences", []),
        }
        
        with open(filename, "wb") as f:
            pickle.dump(data, f)
        
        return filename
        
    except Exception as e:
        st.error(f"Erro ao salvar: {e}")
        return None


def carregar_sessao(uploaded_file):
    """Carrega sessÃ£o de arquivo."""
    try:
        data = pickle.load(uploaded_file)
        
        st.session_state["lista_mensagens"] = data.get("mensagens", [])
        st.session_state["sentiment_history"] = data.get("sentiment_history", [])
        st.session_state["user_corpus_text"] = data.get("corpus", "")
        st.session_state["user_token_sequences"] = data.get("tokens", [])
        
        return True
        
    except Exception as e:
        st.error(f"Erro ao carregar: {e}")
        return False


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURAÃ‡ÃƒO DA INTERFACE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

st.set_page_config(
    page_title="Assistente de Atendimento",
    page_icon="ğŸ§‘â€ğŸ’¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("ğŸ§‘â€ğŸ’¬ Analisador de Conversas com CorreÃ§Ã£o OrtogrÃ¡fica")
st.write("---")
st.caption("â€¢ ğŸ§  Sentimento  â€¢ â˜ï¸ WordCloud  â€¢ ğŸ”— Grafo de Palavras  â€¢ âœï¸ CorreÃ§Ã£o AutomÃ¡tica")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SIDEBAR - CONTROLES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

st.sidebar.title("âš™ï¸ PAINEL DE CONTROLE")

# SeÃ§Ã£o de CorreÃ§Ã£o OrtogrÃ¡fica (NOVO)
st.sidebar.write("### âœï¸ CorreÃ§Ã£o OrtogrÃ¡fica")
correcao_habilitada = st.sidebar.toggle(
    "Ativar correÃ§Ã£o automÃ¡tica",
    value=CONFIG.get("correcao_ortografica", True),
    help="Corrige erros de digitaÃ§Ã£o antes da anÃ¡lise"
)
CONFIG["correcao_ortografica"] = correcao_habilitada

if correcao_habilitada:
    st.sidebar.caption("âœ… Palavras serÃ£o corrigidas automaticamente")
else:
    st.sidebar.caption("âš ï¸ Usando texto original (pode ter erros)")

st.sidebar.write("---")

# Sentimento
st.sidebar.write("### ğŸ§  AnÃ¡lise de Sentimento")
sentimento_habilitado = st.sidebar.toggle(
    "Ativar anÃ¡lise de sentimento",
    value=CONFIG.get("sentimento_habilitado", True),
)

sent_container = st.sidebar.container()
sent_container.caption("Ãšltima mensagem do usuÃ¡rio")

# EvoluÃ§Ã£o do Sentimento
st.sidebar.write("### ğŸ“ˆ EvoluÃ§Ã£o do Sentimento")
with st.sidebar.container():
    _hist = st.session_state.get("sentiment_history", [])
    if _hist:
        _scores = [h.get("score", 0.0) for h in _hist]
        st.line_chart(_scores, height=150, use_container_width=True)
        _last = _hist[-1]
        st.caption(
            f"Mensagens: {len(_scores)} | Ãšltimo: {_last.get('label', '?')} "
            f"({int(float(_last.get('confidence', 0.0)) * 100)}%)"
        )
    else:
        st.info("Envie uma mensagem para ver o grÃ¡fico.")

st.sidebar.write("---")

# WordCloud
st.sidebar.write("### â˜ï¸ Nuvem de Palavras")
wc_container = st.sidebar.container()

col_wc1, col_wc2 = st.sidebar.columns(2)
with col_wc1:
    if st.button("ğŸ—‘ï¸ Limpar nuvem", use_container_width=True):
        st.session_state["user_corpus_text"] = ""
        st.session_state["user_token_sequences"] = []
        st.rerun()

st.sidebar.write("---")

# Grafo
st.sidebar.write("### ğŸ”— Grafo de Palavras")
graph_container = st.sidebar.container()

with graph_container:
    min_edge_weight = st.slider(
        "MÃ­n. coocorrÃªncias (aresta)",
        1, 5, 1,
        help="Filtra arestas fracas"
    )
    
    max_path_depth = st.slider(
        "Profundidade mÃ¡x. caminho",
        1, 8, 4,
        help="Caminhos atÃ© a palavra alvo"
    )
    
    show_paths_only = st.toggle(
        "Mostrar apenas caminhos atÃ© palavra alvo",
        value=True
    )
    
    graph_dark_mode = st.toggle(
        "Modo escuro (grafo)",
        value=True
    )

st.sidebar.write("---")

# AÃ§Ãµes
st.sidebar.write("### ğŸ› ï¸ AÃ§Ãµes")

col1, col2 = st.sidebar.columns(2)
with col1:
    if st.button("ğŸ—‘ï¸ Limpar chat", use_container_width=True):
        st.session_state["lista_mensagens"] = []
        st.session_state["sentimento_atual"] = None
        st.session_state["user_corpus_text"] = ""
        st.session_state["user_token_sequences"] = []
        st.session_state["sentiment_history"] = []
        st.rerun()

with col2:
    if st.button("ğŸ”„ Recarregar", use_container_width=True):
        st.cache_data.clear()
        st.rerun()

# PersistÃªncia
st.sidebar.write("### ğŸ’¾ Salvar/Carregar")

col_save, col_load = st.sidebar.columns(2)
with col_save:
    if st.button("ğŸ’¾ Salvar", use_container_width=True):
        filename = salvar_sessao()
        if filename:
            st.sidebar.success(f"âœ… Salvo: {filename}")

with col_load:
    uploaded = st.sidebar.file_uploader(
        "Carregar sessÃ£o",
        type=["pkl"],
        label_visibility="collapsed"
    )
    if uploaded:
        if carregar_sessao(uploaded):
            st.sidebar.success("âœ… SessÃ£o carregada!")
            st.rerun()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ESTADO DA APLICAÃ‡ÃƒO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if "lista_mensagens" not in st.session_state:
    st.session_state["lista_mensagens"] = []

if "sentimento_atual" not in st.session_state:
    st.session_state["sentimento_atual"] = None

if "user_corpus_text" not in st.session_state:
    st.session_state["user_corpus_text"] = ""

if "user_token_sequences" not in st.session_state:
    st.session_state["user_token_sequences"] = []

if "sentiment_history" not in st.session_state:
    st.session_state["sentiment_history"] = []

if "grafo_html" not in st.session_state:
    st.session_state["grafo_html"] = ""

if "_rerun_flag" not in st.session_state:
    st.session_state["_rerun_flag"] = False

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# RENDERIZAÃ‡ÃƒO DO HISTÃ“RICO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

for msg in st.session_state["lista_mensagens"]:
    if msg["role"] == "user":
        st.chat_message("user").write(msg["content"])
    elif msg["role"] == "assistant":
        st.chat_message("assistant").write(msg["content"])

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ENTRADA DO USUÃRIO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

mensagem_usuario = st.chat_input("ğŸ’­ Digite sua mensagem aqui...")

if mensagem_usuario:
    # Mostra mensagem original
    st.chat_message("user").write(mensagem_usuario)
    
    # NOVO: Mostra correÃ§Ã£o se houver diferenÃ§a
    if correcao_habilitada:
        texto_corrigido = corrigir_texto(mensagem_usuario)
        if texto_corrigido != mensagem_usuario:
            with st.expander("âœï¸ Texto corrigido automaticamente"):
                col_antes, col_depois = st.columns(2)
                with col_antes:
                    st.caption("**Original:**")
                    st.text(mensagem_usuario)
                with col_depois:
                    st.caption("**Corrigido:**")
                    st.text(texto_corrigido)
    else:
        texto_corrigido = mensagem_usuario
        # Adiciona ao histÃ³rico (usa texto corrigido para anÃ¡lises)
    st.session_state["lista_mensagens"].append(
        {"role": "user", "content": texto_corrigido}
    )
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ANÃLISE: Sentimento + TokenizaÃ§Ã£o + Corpus
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    # Tokeniza (jÃ¡ com correÃ§Ã£o aplicada)
    tokens = tokenize_pt(texto_corrigido, corrigir=False)  # JÃ¡ corrigido acima
    
    if tokens:
        # Atualiza corpus para WordCloud
        st.session_state["user_corpus_text"] += " " + " ".join(tokens)
        # Atualiza sequÃªncias para o Grafo
        st.session_state["user_token_sequences"].append(tokens)
    
    # AnÃ¡lise de Sentimento
    if sentimento_habilitado:
        with st.spinner("ğŸ§  Analisando sentimento..."):
            resultado_sentimento = analisar_sentimento(
                texto_corrigido,
                modelo_sentimento=CONFIG["modelo_sentimento"]
            )
            st.session_state["sentimento_atual"] = resultado_sentimento
            
            # Adiciona ao histÃ³rico de sentimentos
            idx_user = sum(
                1 for m in st.session_state["lista_mensagens"]
                if m.get("role") == "user"
            )
            
            st.session_state["sentiment_history"].append({
                "idx": idx_user,
                "label": resultado_sentimento.get("label", "neutro"),
                "confidence": float(resultado_sentimento.get("confidence", 0.0)),
                "score": _score_from_label(
                    resultado_sentimento.get("label", "neutro"),
                    float(resultado_sentimento.get("confidence", 0.0))
                ),
            })
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # RESPOSTA DO ASSISTENTE
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    with st.chat_message("assistant"):
        with st.spinner("ğŸ¤” Pensando na resposta..."):
            # Barra de progresso visual
            progress_bar = st.progress(0)
            for i in range(100):
                time.sleep(0.01)
                progress_bar.progress(i + 1)
            progress_bar.empty()
            
            try:
                # Chama LLM com contexto completo
                resposta = client.chat.completions.create(
                    model=CONFIG["modelo_padrao"],
                    messages=obter_mensagens_completas(),
                    temperature=CONFIG["temperatura_padrao"],
                    max_tokens=CONFIG["max_tokens_padrao"],
                    top_p=0.9,
                    frequency_penalty=0.1,
                )
                
                resposta_ia = resposta.choices[0].message.content or ""
                st.write(resposta_ia)
                
                # Adiciona resposta ao histÃ³rico
                st.session_state["lista_mensagens"].append(
                    {"role": "assistant", "content": resposta_ia}
                )
                
                # Recarrega para atualizar visualizaÃ§Ãµes
                if not st.session_state.get("_rerun_flag"):
                    st.session_state["_rerun_flag"] = True
                    st.rerun()
                else:
                    st.session_state["_rerun_flag"] = False
                
            except Exception as e:
                st.error(f"âŒ Erro na API: {str(e)}")
                st.info("ğŸ’¡ Verifique sua chave API e conexÃ£o com a internet.")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SIDEBAR: VISUALIZAÃ‡Ã•ES ATUALIZADAS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Badge para sentimento
def _badge(label: str) -> str:
    """Cria badge colorido para o sentimento."""
    colors = {
        "positivo": "#16a34a",
        "neutro": "#6b7280",
        "negativo": "#dc2626"
    }
    color = colors.get(label, "#6b7280")
    return (
        f"<span style='background:{color};color:white;padding:4px 10px;"
        f"border-radius:999px;font-weight:600;font-size:12px;'>"
        f"{label.upper()}</span>"
    )


# Atualiza container de sentimento
with sent_container:
    data = st.session_state.get("sentimento_atual")
    
    if sentimento_habilitado and data:
        st.markdown(_badge(data["label"]), unsafe_allow_html=True)
        st.metric("ConfianÃ§a", f"{round(data['confidence'] * 100):d}%")
        
        if data["emotions"]:
            emotes = " ".join([f"`{e}`" for e in data["emotions"][:6]])
            st.write(f"**EmoÃ§Ãµes:** {emotes}")
        
        if data.get("reason"):
            with st.expander("ğŸ“ Justificativa do modelo"):
                st.write(data["reason"])
    
    elif sentimento_habilitado:
        st.info("Envie uma mensagem para ver o sentimento.")


# Atualiza WordCloud
with wc_container:
    corpus = st.session_state.get("user_corpus_text", "")
    
    if corpus.strip():
        buf, err = gerar_wordcloud(corpus)
        
        if err:
            st.warning(err)
        elif buf:
            st.image(buf, caption="Nuvem de Palavras (Corrigidas)", use_container_width=True)
            
            # BotÃ£o de download
            st.download_button(
                "ğŸ“¥ Baixar PNG",
                data=buf,
                file_name=f"wordcloud_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png",
                mime="image/png",
                use_container_width=True,
            )
            
            # EstatÃ­sticas
            tokens_unicos = len(set(corpus.split()))
            tokens_totais = len(corpus.split())
            st.caption(f"ğŸ“Š {tokens_totais} palavras | {tokens_unicos} Ãºnicas")
    else:
        st.info("Digite mensagens para gerar a nuvem.")


# Atualiza Grafo
with graph_container:
    token_seqs = st.session_state.get("user_token_sequences", [])
    
    if not _GRAPH_AVAILABLE:
        st.info("Para ver o grafo, instale:\n```pip install networkx pyvis```")
    
    elif len(token_seqs) == 0:
        st.info("Envie mensagens para gerar o grafo.")
    
    else:
        # ConstrÃ³i grafo completo
        with st.spinner("ğŸ”— Construindo grafo..."):
            G_full = build_word_graph(
                token_seqs,
                min_edge_weight=min_edge_weight,
                max_nodes=500  # Limite de performance
            )
        
        if G_full is None or len(G_full) == 0:
            st.warning("Grafo vazio. Envie mais mensagens.")
        
        else:
            # Aviso de muitos nÃ³s
            if len(G_full.nodes()) >= 500:
                st.warning("âš ï¸ Muitos dados! Mostrando top 500 palavras mais frequentes.")
            
            # Seletor de palavra alvo
            counts = nx.get_node_attributes(G_full, "count")
            words_sorted = sorted(counts.items(), key=lambda x: (-x[1], x[0]))
            top_words = [w for w, c in words_sorted[:200]]
            
            target = st.selectbox(
                "ğŸ¯ Palavra alvo:",
                options=["(nenhuma)"] + top_words,
                help="Destaca a palavra e seus caminhos no grafo"
            )
            
            # Filtra por caminhos se necessÃ¡rio
            G_view = G_full
            
            if show_paths_only and target and target != "(nenhuma)":
                G_tmp = subgraph_paths_to_target(G_full, target, max_depth=max_path_depth)
                
                if G_tmp is not None and len(G_tmp) > 0:
                    G_view = G_tmp
                    st.caption(f"ğŸ” Mostrando {len(G_view.nodes())} nÃ³s conectados a '{target}'")
                else:
                    st.info(f"Nenhum caminho encontrado para '{target}' com profundidade {max_path_depth}.")
                    G_view = None
            
            # Renderiza grafo
            if G_view is not None and len(G_view) > 0:
                html, gerr = render_graph_pyvis(
                    G_view,
                    highlight_target=target if target != "(nenhuma)" else None,
                    height_px=520,
                    dark_mode=graph_dark_mode
                )
                
                if gerr:
                    st.error(gerr)
                else:
                    st.session_state["grafo_html"] = html
                    
                    # Preview do grafo
                    st.components.v1.html(html, height=540, scrolling=True)
                    
                    # EstatÃ­sticas do grafo
                    st.caption(
                        f"ğŸ“Š {len(G_view.nodes())} nÃ³s | "
                        f"{len(G_view.edges())} arestas | "
                        f"Densidade: {nx.density(G_view):.3f}"
                    )
                    
                    # BotÃµes de aÃ§Ã£o
                    col_g1, col_g2 = st.sidebar.columns(2)
                    
                    with col_g1:
                        if st.button("ğŸ“± Expandir", use_container_width=True, key="expand_graph"):
                            st.session_state["grafo_expand_main"] = True
                            st.rerun()
                    
                    with col_g2:
                        # Download HTML
                        st.download_button(
                            "ğŸ“¥ Baixar HTML",
                            data=html,
                            file_name=f"grafo_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html",
                            mime="text/html",
                            use_container_width=True,
                        )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ÃREA PRINCIPAL: GRAFO EXPANDIDO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if st.session_state.get("grafo_expand_main") and st.session_state.get("grafo_html"):
    st.markdown("---")
    st.markdown("## ğŸ”— Grafo de Palavras (VisualizaÃ§Ã£o Expandida)")
    
    st_html(st.session_state["grafo_html"], height=820, scrolling=True)
    
    col_exp1, col_exp2, col_exp3 = st.columns(3)
    
    with col_exp1:
        if st.button("â†©ï¸ Recolher para sidebar", use_container_width=True):
            st.session_state["grafo_expand_main"] = False
            st.rerun()
    
    with col_exp2:
        st.download_button(
            "ğŸ“¥ Baixar HTML do Grafo",
            data=st.session_state["grafo_html"],
            file_name=f"grafo_expandido_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html",
            mime="text/html",
            use_container_width=True,
        )
    
    with col_exp3:
        # EstatÃ­sticas expandidas
        if _GRAPH_AVAILABLE:
            token_seqs = st.session_state.get("user_token_sequences", [])
            G_full = build_word_graph(token_seqs, min_edge_weight=min_edge_weight)
            
            if G_full:
                total_palavras = sum(len(seq) for seq in token_seqs)
                st.metric("Total de Palavras", total_palavras)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# RODAPÃ‰ COM INFORMAÃ‡Ã•ES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

st.markdown("---")

col_info1, col_info2, col_info3 = st.columns(3)

with col_info1:
    st.caption(f"**Modelo:** {CONFIG['modelo_padrao']}")
    st.caption(f"**Temperatura:** {CONFIG['temperatura_padrao']}")

with col_info2:
    total_msgs = len(st.session_state.get("lista_mensagens", []))
    msgs_user = sum(1 for m in st.session_state.get("lista_mensagens", []) if m["role"] == "user")
    st.caption(f"**Mensagens:** {total_msgs} ({msgs_user} do usuÃ¡rio)")

with col_info3:
    if correcao_habilitada:
        st.caption("âœ… **CorreÃ§Ã£o OrtogrÃ¡fica:** Ativa")
    else:
        st.caption("âš ï¸ **CorreÃ§Ã£o OrtogrÃ¡fica:** Desativada")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# EXPORTAÃ‡ÃƒO DE RELATÃ“RIO (NOVO RECURSO)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

st.markdown("---")
st.subheader("ğŸ“Š Exportar RelatÃ³rio de AnÃ¡lise")

col_report1, col_report2 = st.columns(2)

with col_report1:
    if st.button("ğŸ“„ Gerar RelatÃ³rio em Texto", use_container_width=True):
        relatorio = f"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RELATÃ“RIO DE ANÃLISE DE CONVERSAS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Data: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}
Modelo: {CONFIG['modelo_padrao']}

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ESTATÃSTICAS GERAIS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Total de Mensagens: {len(st.session_state.get('lista_mensagens', []))}
Mensagens do UsuÃ¡rio: {sum(1 for m in st.session_state.get('lista_mensagens', []) if m['role'] == 'user')}
Mensagens do Assistente: {sum(1 for m in st.session_state.get('lista_mensagens', []) if m['role'] == 'assistant')}

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ANÃLISE DE SENTIMENTO
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""
        
        hist = st.session_state.get("sentiment_history", [])
        if hist:
            positivos = sum(1 for h in hist if h["label"] == "positivo")
            neutros = sum(1 for h in hist if h["label"] == "neutro")
            negativos = sum(1 for h in hist if h["label"] == "negativo")
            
            relatorio += f"""
Mensagens Positivas: {positivos} ({positivos/len(hist)*100:.1f}%)
Mensagens Neutras: {neutros} ({neutros/len(hist)*100:.1f}%)
Mensagens Negativas: {negativos} ({negativos/len(hist)*100:.1f}%)

Score MÃ©dio: {sum(h['score'] for h in hist)/len(hist):.3f}
ConfianÃ§a MÃ©dia: {sum(h['confidence'] for h in hist)/len(hist)*100:.1f}%
"""
        else:
            relatorio += "\nNenhuma anÃ¡lise de sentimento disponÃ­vel.\n"
        
        relatorio += f"""
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ANÃLISE DE VOCABULÃRIO
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""
        
        corpus = st.session_state.get("user_corpus_text", "")
        if corpus:
            tokens = corpus.split()
            palavras_unicas = set(tokens)
            
            relatorio += f"""
Total de Palavras: {len(tokens)}
Palavras Ãšnicas: {len(palavras_unicas)}
Riqueza Vocabular: {len(palavras_unicas)/len(tokens)*100:.1f}%

Top 10 Palavras Mais Frequentes:
"""
            counter = Counter(tokens)
            for palavra, freq in counter.most_common(10):
                relatorio += f"  {palavra}: {freq} vezes\n"
        
        relatorio += f"""
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# HISTÃ“RICO DE MENSAGENS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""
        
        for i, msg in enumerate(st.session_state.get("lista_mensagens", []), 1):
            role = "USUÃRIO" if msg["role"] == "user" else "ASSISTENTE"
            relatorio += f"\n[{i}] {role}:\n{msg['content']}\n"
        
        relatorio += "\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n"
        
        # Download
        st.download_button(
            "ğŸ“¥ Baixar RelatÃ³rio (.txt)",
            data=relatorio,
            file_name=f"relatorio_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
            mime="text/plain",
            use_container_width=True,
        )

with col_report2:
    if st.button("ğŸ“Š Gerar RelatÃ³rio JSON", use_container_width=True):
        relatorio_json = {
            "metadata": {
                "data_geracao": datetime.now().isoformat(),
                "modelo": CONFIG["modelo_padrao"],
                "temperatura": CONFIG["temperatura_padrao"],
                "correcao_ortografica": correcao_habilitada,
            },
            "estatisticas": {
                "total_mensagens": len(st.session_state.get("lista_mensagens", [])),
                "mensagens_usuario": sum(1 for m in st.session_state.get("lista_mensagens", []) if m["role"] == "user"),
                "mensagens_assistente": sum(1 for m in st.session_state.get("lista_mensagens", []) if m["role"] == "assistant"),
            },
            "sentimento": {
                "historico": st.session_state.get("sentiment_history", []),
            },
            "vocabulario": {
                "corpus": st.session_state.get("user_corpus_text", ""),
                "sequencias_tokens": st.session_state.get("user_token_sequences", []),
            },
            "mensagens": st.session_state.get("lista_mensagens", []),
        }
        
        json_str = json.dumps(relatorio_json, ensure_ascii=False, indent=2)
        
        st.download_button(
            "ğŸ“¥ Baixar RelatÃ³rio (.json)",
            data=json_str,
            file_name=f"relatorio_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json",
            use_container_width=True,
        )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DICAS E AJUDA
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

with st.expander("ğŸ’¡ Dicas de Uso"):
    st.markdown("""
    ### Como usar este assistente:
    
    **ğŸ”§ CorreÃ§Ã£o OrtogrÃ¡fica**
    - Ative na sidebar para corrigir automaticamente erros de digitaÃ§Ã£o
    - CorreÃ§Ãµes comuns: "vc" â†’ "vocÃª", "tbm" â†’ "tambÃ©m", "nao" â†’ "nÃ£o"
    - O texto corrigido Ã© usado para todas as anÃ¡lises (sentimento, grafo, wordcloud)
    
    **ğŸ§  AnÃ¡lise de Sentimento**
    - Cada mensagem sua Ã© analisada em tempo real
    - Verde = Positivo | Cinza = Neutro | Vermelho = Negativo
    - O grÃ¡fico mostra a evoluÃ§Ã£o do sentimento ao longo da conversa
    
    **â˜ï¸ Nuvem de Palavras**
    - Palavras maiores = mais frequentes
    - Apenas suas mensagens sÃ£o consideradas
    - Use "Limpar nuvem" para comeÃ§ar do zero
    
    **ğŸ”— Grafo de Palavras**
    - Mostra como palavras aparecem juntas (coocorrÃªncias)
    - NÃ³s maiores = palavras mais frequentes
    - Linhas mais grossas = palavras que aparecem juntas com frequÃªncia
    - Use "Palavra alvo" para destacar conexÃµes especÃ­ficas
    
    **ğŸ’¾ Salvar/Carregar**
    - Salve sua sessÃ£o para continuar depois
    - O arquivo .pkl contÃ©m todo o histÃ³rico e anÃ¡lises
    
    **ğŸ“Š RelatÃ³rios**
    - Exporte anÃ¡lises completas em TXT ou JSON
    - Ideal para documentaÃ§Ã£o ou anÃ¡lise posterior
    """)

with st.expander("âš™ï¸ ConfiguraÃ§Ãµes AvanÃ§adas"):
    st.markdown("""
    ### ParÃ¢metros do Sistema:
    
    **Modelo:** `{modelo}`
    - Define qual modelo da OpenAI serÃ¡ usado
    - Modelos menores (gpt-4o-mini) sÃ£o mais rÃ¡pidos e baratos
    - Modelos maiores (gpt-4o) sÃ£o mais precisos
    
    **Temperatura:** `{temp}`
    - Controla criatividade das respostas (0.0 a 1.0)
    - Valor baixo = respostas mais determinÃ­sticas
    - Valor alto = respostas mais variadas
    
    **Limite de Contexto:** `{contexto}` mensagens
    - Quantas mensagens anteriores sÃ£o enviadas Ã  API
    - Mais contexto = melhor memÃ³ria, mas mais caro
    
    **CorreÃ§Ã£o OrtogrÃ¡fica:**
    - DicionÃ¡rio com {qtd_correcoes} correÃ§Ãµes comuns
    - Processamento local (sem custo de API)
    - Fallback para LLM em casos complexos
    """.format(
        modelo=CONFIG["modelo_padrao"],
        temp=CONFIG["temperatura_padrao"],
        contexto=CONFIG["max_contexto_mensagens"],
        qtd_correcoes=len(CORREÃ‡Ã•ES_ORTOGRÃFICAS)
    ))


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FOOTER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

st.markdown("---")
st.caption(
    "ğŸ¤– Assistente de Atendimento com IA | "
    "Powered by OpenAI | "
    f"VersÃ£o 2.0 | "
    f"{datetime.now().strftime('%Y')}"
)